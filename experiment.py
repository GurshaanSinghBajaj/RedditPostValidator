# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JjYkDEWgWNJOzBy4o7qELWEMw-DuOcEa
"""

#!pip install bert-for-tf2 >> /dev/null
#!pip install tqdm  >> /dev/null
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import bert
import os
import os
import math
import datetime

from tqdm import tqdm

import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow import keras

import bert
from bert import BertModelLayer
from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights
from bert.tokenization.bert_tokenization import FullTokenizer

# from google.colab import drive
# drive.mount('/gdrive')

import os
import math
import datetime

from tqdm import tqdm

import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow import keras

import bert
from bert import BertModelLayer
from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights
from bert.tokenization.bert_tokenization import FullTokenizer

#!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip
#!unzip uncased_L-12_H-768_A-12.zip

#os.makedirs("model", exist_ok=True)
#!mv uncased_L-12_H-768_A-12/ model
bert_model_name="uncased_L-12_H-768_A-12"

bert_ckpt_dir = os.path.join("model/", bert_model_name)
bert_ckpt_file = os.path.join(bert_ckpt_dir, "bert_model.ckpt")
bert_config_file = os.path.join(bert_ckpt_dir, "bert_config.json")

class DataProcessor:
  DATA_COLUMN = "Headline"
  LABEL_COLUMN = "Stance"

  def __init__(self, test, tokenizer: FullTokenizer, classes, max_seq_len=512):
    self.tokenizer = tokenizer
    self.classes = classes
    self.max_seq_len = max_seq_len

    self.test_x, self.test_y = self._prepare(test)

    #print("max seq_len", self.max_seq_len)
    ##print(self.test_x)
    self.test_x = self._pad(self.test_x)

  def _prepare(self, df):
    x, y = [], []

    for _, row in tqdm(df.iterrows()):
      text, label = row[DataProcessor.DATA_COLUMN], row[DataProcessor.LABEL_COLUMN]
      tokens = self.tokenizer.tokenize(text)
      tokens = ["[CLS]"] + tokens + ["[SEP]"]
      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)
      x.append(token_ids)
      y.append(self.classes.index(label))
    return np.array(x), np.array(y)

  def _pad(self, ids):
    x = []
    for input_ids in ids:
        input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]
        z=self.max_seq_len - len(input_ids)
        y=[0]
        y=np.array(y)
        for i in range(z):
            input_ids=np.append(input_ids,y)
        x.append(np.array(input_ids))
    return np.array(x)

tokenizer = FullTokenizer(
  vocab_file=os.path.join(bert_ckpt_dir, "vocab.txt")
)

data = [["What would you do if you found undeniable evidence that the universe is just a simulation and you were the only one who knew? There’s an argument that if people in a simulation figure out that they are in a simulation, then it could ruin the purpose of whatever the simulation is being run for. and it’ll just be turned off. So keep quiet.,Edit: here’s a paper on this by Preston Greene, for those interested. https://philpapers.org/rec/GRETTR-5. I heard about it via this Robert Wright interview: https://meaningoflife.tv/videos/42317", "agree"]]

test_df= pd.DataFrame(data, columns = ['Headline', 'Stance'])

#test_df.head()

classes = ['unrelated', 'discuss', 'agree', 'disagree']

data = DataProcessor(test_df, tokenizer, classes, max_seq_len=512)

#print(data.test_x)

from tensorflow.keras.models import load_model
model = load_model('bert.h5', custom_objects={"BertModelLayer": bert.BertModelLayer})

prediction = model.predict(data.test_x).argmax(axis=-1)

print(prediction[0])
